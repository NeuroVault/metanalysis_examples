{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\Miniconda3\\lib\\importlib\\_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "from nilearn.image import resample_to_img, math_img\n",
    "from nilearn.datasets import load_mni152_template, load_mni152_brain_mask\n",
    "import nibabel as nb\n",
    "from gzip import GzipFile\n",
    "from nimare.meta.ibma import stouffers, weighted_stouffers\n",
    "from nilearn.masking import apply_mask\n",
    "from nilearn.plotting import plot_roi, plot_stat_map, plot_glass_brain\n",
    "\n",
    "template_nii = load_mni152_template()\n",
    "template_mask_nii = load_mni152_brain_mask()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial shows how to use NeuroVault API and NiMARE to perfroma a metaanalysis on a set of single subject maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining which images will be used in the metaanalysis\n",
    "We begin by creating a helper function to get metadata for all images that are part of a set of collections we are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_metadata(collection_ids):\n",
    "    images = []\n",
    "    for collection_id in collection_ids:\n",
    "        url = \"http://neurovault.org/api/collections/%d/images/?format=json\"%collection_id\n",
    "        while url:\n",
    "            r = requests.get(url)\n",
    "            d = r.json()\n",
    "            images += d['results']\n",
    "            url = d['next']\n",
    "    return pd.DataFrame(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this excercise we are coing to use only one collection but this list can be extended to multiple collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_ids = [3235]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BMI', 'SDS-BMI', 'add_date', 'age', 'analysis_level', 'bis11_score',\n",
       "       'bis_bas_score', 'brain_coverage', 'cognitive_contrast_cogatlas',\n",
       "       'cognitive_contrast_cogatlas_id', 'cognitive_paradigm_cogatlas',\n",
       "       'cognitive_paradigm_cogatlas_id', 'cognitive_paradigm_description_url',\n",
       "       'collection', 'collection_id', 'contrast_definition',\n",
       "       'contrast_definition_cogatlas', 'data_origin',\n",
       "       'days_since_menstruation', 'description', 'ethnicity', 'fat_percentage',\n",
       "       'figure', 'file', 'file_size', 'gender', 'handedness',\n",
       "       'hours_since_last_meal', 'id', 'image_type', 'is_thresholded',\n",
       "       'is_valid', 'map_type', 'mean_PDS_score', 'modality', 'modify_date',\n",
       "       'name', 'not_mni', 'number_of_subjects', 'perc_bad_voxels',\n",
       "       'perc_voxels_outside', 'race', 'reduced_representation',\n",
       "       'smoothness_fwhm', 'spsrq_score', 'statistic_parameters',\n",
       "       'subject_species', 'surface_left_file', 'surface_right_file',\n",
       "       'tanner_stage', 'target_template_image', 'thumbnail', 'url',\n",
       "       'waist_hip_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images_df = get_images_metadata(collection_ids)\n",
    "all_images_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function returns a Pandas DataFrame with all metadata associated with the images. This way we can filter what images should go into our metaanalysis. We will only use single subject maps from this collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>age</th>\n",
       "      <th>brain_coverage</th>\n",
       "      <th>collection_id</th>\n",
       "      <th>file_size</th>\n",
       "      <th>id</th>\n",
       "      <th>number_of_subjects</th>\n",
       "      <th>perc_bad_voxels</th>\n",
       "      <th>perc_voxels_outside</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>67.00000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>23.19194</td>\n",
       "      <td>33.516885</td>\n",
       "      <td>90.553975</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>112867.745902</td>\n",
       "      <td>108309.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.678171</td>\n",
       "      <td>8.238074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.93002</td>\n",
       "      <td>23.084441</td>\n",
       "      <td>2.953555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4457.423544</td>\n",
       "      <td>35.362409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.923337</td>\n",
       "      <td>2.965284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>19.52000</td>\n",
       "      <td>8.430000</td>\n",
       "      <td>80.609283</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>102708.000000</td>\n",
       "      <td>108249.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.379708</td>\n",
       "      <td>2.867370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.69500</td>\n",
       "      <td>14.737500</td>\n",
       "      <td>89.051625</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>109903.000000</td>\n",
       "      <td>108279.250000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.130732</td>\n",
       "      <td>5.964508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>23.37000</td>\n",
       "      <td>26.615000</td>\n",
       "      <td>91.130076</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>112553.500000</td>\n",
       "      <td>108309.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.698576</td>\n",
       "      <td>8.218514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.54000</td>\n",
       "      <td>59.022500</td>\n",
       "      <td>92.200343</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>115561.750000</td>\n",
       "      <td>108339.750000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>77.239783</td>\n",
       "      <td>10.027860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>26.93000</td>\n",
       "      <td>76.060000</td>\n",
       "      <td>96.642300</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>124164.000000</td>\n",
       "      <td>108370.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>78.883639</td>\n",
       "      <td>17.852171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            BMI         age  brain_coverage  collection_id      file_size  \\\n",
       "count  67.00000  122.000000      122.000000          122.0     122.000000   \n",
       "mean   23.19194   33.516885       90.553975         3235.0  112867.745902   \n",
       "std     1.93002   23.084441        2.953555            0.0    4457.423544   \n",
       "min    19.52000    8.430000       80.609283         3235.0  102708.000000   \n",
       "25%    21.69500   14.737500       89.051625         3235.0  109903.000000   \n",
       "50%    23.37000   26.615000       91.130076         3235.0  112553.500000   \n",
       "75%    24.54000   59.022500       92.200343         3235.0  115561.750000   \n",
       "max    26.93000   76.060000       96.642300         3235.0  124164.000000   \n",
       "\n",
       "                  id  number_of_subjects  perc_bad_voxels  perc_voxels_outside  \n",
       "count     122.000000               122.0       122.000000           122.000000  \n",
       "mean   108309.500000                 1.0        76.678171             8.238074  \n",
       "std        35.362409                 0.0         0.923337             2.965284  \n",
       "min    108249.000000                 1.0        74.379708             2.867370  \n",
       "25%    108279.250000                 1.0        76.130732             5.964508  \n",
       "50%    108309.500000                 1.0        76.698576             8.218514  \n",
       "75%    108339.750000                 1.0        77.239783            10.027860  \n",
       "max    108370.000000                 1.0        78.883639            17.852171  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_images_df = all_images_df[all_images_df.analysis_level == 'single-subject']\n",
    "ss_images_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing the metaanalysis\n",
    "We begin by defining a helper function that takes a Dataframe of selected images and performs Stouffer's metaanalysis on them.\n",
    "\n",
    "**Disclaimer: the maps in this example are T maps which is technically incorrect for this technique. Without knowing the first level desing it is impossible to asses the degrees of freedom and convert them to Z maps, but for the sake of this excercise we will assume T == Z**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_metaanalysis(images_df):\n",
    "    z_imgs = []\n",
    "    for i, row in images_df.iterrows():\n",
    "        download_url = row['file']\n",
    "        print(\"Downloading %s\"%download_url)\n",
    "        r = requests.get(download_url)\n",
    "        fp = io.BytesIO(r.content)\n",
    "        gzfileobj = GzipFile(filename=\"tmp.nii.gz\", mode='rb', fileobj=fp)\n",
    "        nii = nb.Nifti1Image.from_file_map({'image': nb.FileHolder(\"tmp.nii.gz\", gzfileobj)})\n",
    "\n",
    "        # making sure all images have the same size\n",
    "        resampled_nii = resample_to_img(nii, template_nii)\n",
    "        z_imgs.append(resampled_nii)\n",
    "\n",
    "    z_data = apply_mask(z_imgs, template_mask_nii)\n",
    "    results = stouffers(z_data, template_mask_nii, inference='ffx', null='theoretical', corr='FWE', two_sided=True)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function downloads the selected maps and resamples them to match dimensions of the MNI template. Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_AN001_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_AN002_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_AN003_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_AN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_AN005_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_AN006_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_AN007_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_AN008_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_EN001_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_EN002_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_EN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_EN005_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_EN006_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_EN007_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_TN001_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_TN003_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_TN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_TN005_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_AB_TN006_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN001_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN002_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN003_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN005_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN006_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN007_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN009_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_AN052_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_EN005_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_EN007_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_EN008_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_TN001_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_TN002_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_TN003_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_TN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_TN009_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_TN011_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_GR_TN012_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN001_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN002_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN003_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN005_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN008_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN009_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN011_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN013_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN014_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN016_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN018_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN019_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN021_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN023_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN024_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN025_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN026_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_AN027_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN003_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN007_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN009_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN010_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN011_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN012_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN013_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN014_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN016_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN017_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN020_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN021_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN022_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN027_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN029_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_CN030_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN001_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN002_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN003_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN005_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN006_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN007_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN008_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN010_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN011_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN012_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN013_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN014_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN015_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN016_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN017_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN018_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN019_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN020_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN021_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN022_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_EN023_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_TN001_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_TN002_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_TN003_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_TN004_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_TN005_H.nii.gz\n",
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_TN006_H.nii.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://neurovault.org/media/images/3235/spmT_0002_NL_TN007_H.nii.gz\n"
     ]
    }
   ],
   "source": [
    "results = perform_metaanalysis(ss_images_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.images.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we can plot the statistically significan ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roi(math_img(formula = '(a < 0.05)*mask', a=results.images['p'], mask=template_mask_nii))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering with metadata\n",
    "Because the DataFrame includes metadata we can use them to filter the images going into the metaanalysis. Lets showcase this, by redoing the above metaanalysis only with data from participants over 18 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_above_18_df = ss_images_df[ss_images_df.age > 18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ss_above_18_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = perform_metaanalysis(ss_above_18_df)\n",
    "plot_roi(math_img(formula = '(a < 0.05)*mask', a=results.images['p'], mask=template_mask_nii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
